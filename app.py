"""
Audio2Tekst
=======================================

Ten modu≈Ç zawiera implementacjƒô aplikacji Streamlit do transkrypcji
plik√≥w audio i video na tekst oraz generowania ich podsumowa≈Ñ.

üöÄ WERSJA 2.2.0 - ENTERPRISE EDITION (ENHANCED) üöÄ
- Finalna wersja z kompletnƒÖ infrastrukturƒÖ enterprise
- Dodano enterprise-level dokumentacjƒô i CI/CD
- Implementowano kompletny system test√≥w i security scanning
- Przeprowadzono refaktoryzacjƒô kodu z poprawkami b≈Çƒôd√≥w
- Dodano professional project structure i GitHub templates
- Kolejna poprawiona wersja z pe≈ÇnƒÖ profesjonalnƒÖ strukturƒÖ

Autor: Alan Steinbarth (alan.steinbarth@gmail.com)
GitHub: https://github.com/AlanSteinbarth
Data: 26 maja 2025
Wersja: 2.2.0 (Enterprise Edition Enhanced)
"""

# --- Importy systemowe ---
import hashlib
import logging
import re
import math
import tempfile
import os
import shutil
import subprocess
from pathlib import Path

# --- Importy zewnƒôtrzne ---
import streamlit as st
import openai
from werkzeug.utils import secure_filename
import yt_dlp

# --- Konfiguracja logowania ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- Konfiguracja Streamlit ---
st.set_page_config(page_title="Audio2Tekst", layout="wide")
st.title('üìºAudio2Tekstüìù')
st.subheader("Przekszta≈Çƒá swoje pliki audio i video (oraz z YouTube) na tekst, a nastƒôpnie zr√≥b z nich zwiƒôz≈Çe podsumowanie" )

# --- Konfiguracja OpenAI ---
api_key = st.sidebar.text_input("Podaj sw√≥j OpenAI API Key", type="password")
if not api_key:
    st.stop()
client = openai.OpenAI(api_key=api_key)

# --- Sta≈Çe i konfiguracja ≈õcie≈ºek ---
BASE_DIR = Path("uploads")
for folder in ("originals", "transcripts", "summaries"):
    (BASE_DIR / folder).mkdir(parents=True, exist_ok=True)
ALLOWED_EXT = {".mp3", ".wav", ".m4a", ".mp4", ".mov", ".avi", ".webm"}
MAX_SIZE = 25 * 1024 * 1024  # 25MB
CHUNK_MS = 5 * 60 * 1000     # 5 minutes in ms

# --- Funkcje pomocnicze ---
# UWAGA: To jest ulepszona wersja programu Audio2Tekst
# G≈Ç√≥wne usprawnienia w wersji 2.2.0:
# ‚úÖ Finalna wersja enterprise z kompletnƒÖ infrastrukturƒÖ
# ‚úÖ Naprawiono b≈Çƒôdy z brakujƒÖcymi parametrami _client w funkcjach cache
# ‚úÖ Dodano enterprise-level dokumentacjƒô i CI/CD pipeline
# ‚úÖ Implementowano comprehensive testing suite
# ‚úÖ Dodano security scanning i quality assurance
# ‚úÖ Przeprowadzono refaktoryzacjƒô kodu dla lepszej maintainability
# ‚úÖ Dodano professional GitHub templates i community guidelines
# ‚úÖ Kolejna poprawiona wersja z pe≈ÇnƒÖ profesjonalnƒÖ strukturƒÖ

@st.cache_data
def init_paths(data: bytes, ext: str):
    """Inicjalizuje ≈õcie≈ºki dla plik√≥w na podstawie zawarto≈õci."""
    uid = hashlib.md5(data).hexdigest()
    orig = BASE_DIR / "originals" / f"{uid}{ext}"
    tr = BASE_DIR / "transcripts" / f"{uid}.txt"
    sm = BASE_DIR / "summaries" / f"{uid}.txt"
    if not orig.exists():
        orig.write_bytes(data)
    return uid, orig, tr, sm

@st.cache_data
def download_youtube_audio(url: str):
    """Pobiera audio z filmu YouTube i konwertuje do odpowiedniego formatu."""
    tmpdir = tempfile.mkdtemp()
    opts = {
        'format': 'bestaudio[ext=webm]/bestaudio',
        'outtmpl': os.path.join(tmpdir, '%(id)s.%(ext)s'),
        'quiet': True,
        'noplaylist': True
    }
    with yt_dlp.YoutubeDL(opts) as ydl:
        ydl.download([url])
    for f in Path(tmpdir).iterdir():
        if f.suffix.lower() in ALLOWED_EXT:
            data = f.read_bytes()
            shutil.rmtree(tmpdir)
            return data, f.suffix.lower()
    shutil.rmtree(tmpdir)
    raise FileNotFoundError("Nie znaleziono pliku audio z YouTube")

@st.cache_data
def get_duration(path: Path) -> float:
    """Zwraca d≈Çugo≈õƒá pliku audio/video w sekundach."""
    cmd = [
        'ffprobe', '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        str(path)
    ]
    out = subprocess.run(cmd, capture_output=True, text=True)
    return float(out.stdout.strip())

@st.cache_data
def split_audio(path: Path):
    """Dzieli d≈Çugie pliki audio na mniejsze czƒô≈õci do przetworzenia."""
    duration = get_duration(path)
    seg_sec = CHUNK_MS / 1000
    parts = []
    for i in range(math.ceil(duration / seg_sec)):
        start = i * seg_sec
        length = seg_sec if (start + seg_sec) <= duration else (duration - start)
        fd, tmp = tempfile.mkstemp(suffix=path.suffix)
        os.close(fd)
        tmp_path = Path(tmp)
        cmd = [
            'ffmpeg', '-y', '-i', str(path),
            '-ss', str(start), '-t', str(length),
            '-c', 'copy', str(tmp_path)
        ]
        subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        parts.append(tmp_path)
    return parts

@st.cache_data
def clean_transcript(text: str) -> str:
    """Czy≈õci transkrypcjƒô z typowych artefakt√≥w mowy."""
    text = re.sub(r"\b(?:em|yhm|um|uh|a{2,}|y{2,})\b", "", text, flags=re.IGNORECASE)
    text = re.sub(r"\s+", " ", text)
    return text.strip()

@st.cache_data
def transcribe_chunks(chunks, _client):
    """Transkrybuje podzielone fragmenty audio na tekst u≈ºywajƒÖc OpenAI API."""
    texts = []
    for c in chunks:
        if c.stat().st_size <= MAX_SIZE:
            with open(c, 'rb') as f:
                res = _client.audio.transcriptions.create(
                    model='whisper-1',
                    file=f,
                    language='pl',
                    response_format='text'
                )
                texts.append(clean_transcript(str(res)))
        c.unlink()
    return "\n".join(texts)

@st.cache_data
def summarize(text: str, _client):
    """Generuje temat i podsumowanie z transkrypcji."""
    try:
        prompt = "Podaj temat w jednym zdaniu i podsumowanie 3-5 zdaniami:\n" + text
        completion = _client.chat.completions.create(
            model='gpt-3.5-turbo',
            messages=[{'role': 'user', 'content': prompt}],
            max_tokens=300
        )
        if completion and completion.choices and completion.choices[0].message:
            content = completion.choices[0].message.content
            lines = content.splitlines() if content else []
            topic = lines[0] if lines else 'Nie uda≈Ço siƒô wygenerowaƒá tematu'
            summary = ' '.join(lines[1:]) if len(lines) > 1 else 'Nie uda≈Ço siƒô wygenerowaƒá podsumowania'
            return topic, summary
    except Exception as e:
        logger.error(f"B≈ÇƒÖd podczas generowania podsumowania: {str(e)}")
        return "B≈ÇƒÖd podczas generowania podsumowania", str(e)
    return "Nie uda≈Ço siƒô wygenerowaƒá podsumowania", "Spr√≥buj ponownie lub skontaktuj siƒô z administratorem"

# --- Interfejs u≈ºytkownika ---
src = st.sidebar.radio('Wybierz ≈∫r√≥d≈Ço audio:', ['Plik lokalny', 'YouTube'])
if src == 'YouTube':
    url = st.sidebar.text_input('Wklej adres www z YouTube:') or st.stop()
    data, ext = download_youtube_audio(url)
else:
    up = st.sidebar.file_uploader('Wybierz plik', type=[e.strip('.') for e in ALLOWED_EXT]) or st.stop()
    data, ext = up.read(), Path(secure_filename(up.name)).suffix.lower()

# --- Przetwarzanie pliku ---
uid, orig, tr, sm = init_paths(data, ext)
st.audio(orig.read_bytes(), format=ext.lstrip('.'))

# --- Stan sesji ---
done_key = f"done_{uid}"
topic_key = f"topic_{uid}"
sum_key = f"summary_{uid}"
for key, default in [(done_key, False), (topic_key, ''), (sum_key, '')]:
    if key not in st.session_state:
        st.session_state[key] = default

# --- Transkrypcja ---
if st.button('Transkrybuj') and not st.session_state[done_key]:
    # dzielenie i transkrypcja
    chunks = split_audio(orig)
    text = transcribe_chunks(chunks, client)
    tr.write_text(text, encoding='utf-8')
    st.session_state[done_key] = True

# --- Wy≈õwietlanie wynik√≥w ---
if st.session_state[done_key]:
    transcript = tr.read_text(encoding='utf-8')
    st.text_area('Transkrypt (mo≈ºesz edytowaƒá tekst i p√≥≈∫niej go zapisaƒá)', transcript, height=300)
    st.download_button('Pobierz transkrypt', transcript, file_name=tr.name)    # Generowanie podsumowania
    if st.button('Podsumuj') and not st.session_state[topic_key]:
        t, s = summarize(transcript, client)
        sm.write_text(f"{t}\n\n{s}", encoding='utf-8')
        st.session_state[topic_key] = t
        st.session_state[sum_key] = s

# --- Wy≈õwietlanie podsumowania ---
if st.session_state[topic_key]:
    st.subheader('Temat')
    st.write(st.session_state[topic_key])
    st.subheader('Podsumowanie')
    st.write(st.session_state[sum_key])
    st.download_button('Pobierz podsumowanie', f"{st.session_state[topic_key]}\n\n{st.session_state[sum_key]}", file_name=sm.name)
