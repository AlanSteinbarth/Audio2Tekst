# üèóÔ∏è Architektura Audio2Tekst

## üìä Diagram systemu

```mermaid
graph TD
    A[üë§ U≈ºytkownik] --> B[üåê Streamlit UI]
    B --> C{üìÅ ≈πr√≥d≈Ço audio}
    C -->|Plik lokalny| D[üìÇ Upload pliku]
    C -->|YouTube| E[üé¨ yt-dlp downloader]
    
    D --> F[üîß FFmpeg Processing]
    E --> F
    F --> G[‚úÇÔ∏è Audio Chunking]
    G --> H[üéß OpenAI Whisper API]
    H --> I[üìù Transkrypcja]
    I --> J[ü§ñ GPT-3.5 Summarization]
    J --> K[üíæ Export & Storage]
    K --> L[üì§ Download Results]
```

## üîÑ Przep≈Çyw danych

1. **Input** ‚Üí User uploads file lub podaje YouTube URL
2. **Processing** ‚Üí FFmpeg konwertuje do MP3, dzieli na chunki
3. **Transcription** ‚Üí Whisper API transkrybuje ka≈ºdy chunk
4. **AI Summary** ‚Üí GPT-3.5 generuje temat i podsumowanie
5. **Output** ‚Üí U≈ºytkownik pobiera transkrypcjƒô i podsumowanie

## üõ°Ô∏è Bezpiecze≈Ñstwo

- API keys przez environment variables
- Walidacja format√≥w plik√≥w
- Automatyczne czyszczenie plik√≥w tymczasowych
- Rate limiting dla API calls

## ‚ö° Optymalizacje

- Chunking dla du≈ºych plik√≥w (>25MB)
- Streamlit caching dla lepszej wydajno≈õci
- Asynchroniczne przetwarzanie UI
- Cross-platform compatibility layer
